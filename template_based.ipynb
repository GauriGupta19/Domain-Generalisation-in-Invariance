{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af39f16-f17f-4cf0-b763-8606d9d731ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load utility functions for data loading and preprocessing\n",
    "from typing import Optional, Tuple, Type, Union\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a6784a-bd44-44bf-9551-45671988533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist(dataset) -> Tuple[torch.Tensor]:\n",
    "    # !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "    # !tar -zxvf MNIST.tar.gz\n",
    "    imstack_data_r = torch.zeros_like(dataset.data, dtype=torch.float32)\n",
    "    labels = []\n",
    "    for i, (im, lbl) in enumerate(dataset):\n",
    "        imstack_data_r[i] = ToTensor()(im)\n",
    "        labels.append(lbl)\n",
    "    imstack_data_r /= imstack_data_r.max()\n",
    "    return imstack_data_r, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c0924-fce8-4a57-8348-b9595e3f91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotated_mnist(dataset, rotation_range: Tuple[int]) -> Tuple[torch.Tensor]:\n",
    "    # !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "    # !tar -zxvf MNIST.tar.gz\n",
    "    imstack_data_r = torch.zeros_like(dataset.data, dtype=torch.float32)\n",
    "    labels, angles = [], []\n",
    "    for i, (im, lbl) in enumerate(dataset):\n",
    "        theta = torch.randint(*rotation_range, (1,)).float()\n",
    "        im = im.rotate(theta.item(), resample=Image.BICUBIC)\n",
    "        imstack_data_r[i] = ToTensor()(im)\n",
    "        labels.append(lbl)\n",
    "        angles.append(torch.deg2rad(theta))\n",
    "    imstack_data_r /= imstack_data_r.max()\n",
    "    return imstack_data_r, torch.tensor(labels), torch.tensor(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e294df0-c451-42dd-97af-0a70bde984ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_half_labels_rotated_mnist2(dataset, rotation_range: Tuple[int]) -> Tuple[torch.Tensor]:\n",
    "    # !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "    # !tar -zxvf MNIST.tar.gz\n",
    "    data, labels, angles = [], [], []\n",
    "    count = torch.zeros(10)\n",
    "    for i, (im, lbl) in enumerate(dataset):\n",
    "        if lbl<5:\n",
    "            if count[lbl]<1000:\n",
    "                theta = torch.randint(*rotation_range, (1,)).float()\n",
    "                im = im.rotate(theta.item(), resample=Image.BICUBIC)\n",
    "                data.append(ToTensor()(im))\n",
    "                labels.append(lbl)\n",
    "                angles.append(torch.deg2rad(theta))\n",
    "                count[lbl] = count[lbl]+1\n",
    "        else:\n",
    "            if count[lbl]<1000:\n",
    "                data.append(ToTensor()(im))\n",
    "                labels.append(lbl)\n",
    "                angles.append(0)\n",
    "                count[lbl] = count[lbl]+1\n",
    "    return torch.cat(data), torch.tensor(labels), torch.tensor(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04ee57-5e12-448c-a2d9-59af1c0339ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataloader(*args: torch.Tensor, **kwargs: int\n",
    "                    ) -> Type[torch.utils.data.DataLoader]:\n",
    "\n",
    "    batch_size = kwargs.get(\"batch_size\", 100)\n",
    "    tensor_set = torch.utils.data.dataset.TensorDataset(*args)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=tensor_set, batch_size=batch_size, shuffle=True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189264aa-33da-4609-9691-958a8ace808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.optim import Adam\n",
    "import dataclasses\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "LR = 6e-4\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels= 300, out_channels=5, num_hidden=128):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels,num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden,num_hidden)\n",
    "        self.fc3 = nn.Linear(num_hidden,out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x=torch.flatten(x, start_dim=1) # Flatten layer\n",
    "        x=F.relu(self.fc1(x)) \n",
    "        x=F.relu(self.fc2(x)) \n",
    "        x=F.softmax(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "def train_nn(model, template0, template1, template2, train_dataset, test_dataset, batch_size=32, num_epochs=NUM_EPOCHS, lr=LR, criterion=nn.CrossEntropyLoss()):\n",
    "    \n",
    "    TrainResult = {'train_losses': [], 'val_accs': []}\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train = 0\n",
    "        model.train()\n",
    "        for datapoint in tqdm(train_loader):\n",
    "            X, y = datapoint[0].to(device), datapoint[1].to(device)\n",
    "            batch_len = X.shape[0]\n",
    "            X = X.view(-1, batch_len)    \n",
    "            emb0 = torch.mm(template0.to(device), X)\n",
    "            emb0 = [torch.histc(emb0[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb0 = torch.stack(emb0)\n",
    "            emb1 = torch.mm(template1.to(device), X)\n",
    "            emb1 = [torch.histc(emb1[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb1 = torch.stack(emb1)\n",
    "            emb2 = torch.mm(template2.to(device), X)\n",
    "            emb2 = [torch.histc(emb2[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb2 = torch.stack(emb2)\n",
    "            emb = torch.cat((emb0, emb1, emb2), dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(emb)\n",
    "            loss = criterion(output, y)\n",
    "            total_train += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_train = total_train/len(train_loader)\n",
    "        TrainResult['train_losses'].append(total_train)\n",
    "                               \n",
    "        model.eval()\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for bidx, datapoint in enumerate(test_loader):\n",
    "                X, y = datapoint[0].to(device), datapoint[1].to(device)\n",
    "                batch_len = X.shape[0]\n",
    "                X = X.view(-1, batch_len)    \n",
    "                emb0 = torch.mm(template0.to(device), X)\n",
    "                emb0 = [torch.histc(emb0[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "                emb0 = torch.stack(emb0)\n",
    "                emb1 = torch.mm(template1.to(device), X)\n",
    "                emb1 = [torch.histc(emb1[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "                emb1 = torch.stack(emb1)\n",
    "                emb2 = torch.mm(template2.to(device), X)\n",
    "                emb2 = [torch.histc(emb2[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "                emb2 = torch.stack(emb2)\n",
    "                emb = torch.cat((emb0, emb1, emb2), dim=1)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(emb)\n",
    "                total_val += torch.sum(torch.argmax(output, dim=-1)==y).item()/output.size(dim=0)\n",
    "        TrainResult['val_accs'].append(total_val/len(test_loader))\n",
    "        print(\"Epoch {}: Train Loss={} Validation Accuracy={}%\".format(epoch, TrainResult['train_losses'][-1], TrainResult['val_accs'][-1]*100))\n",
    "    return TrainResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13a5456-e87d-4fa1-8201-433cef7de320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = train_nn(model, temp0, temp1, mnist_trainset, mnist_testset, num_epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5b483-b92a-4cdf-a4fb-8cd264a5bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST('data/mnist/', train=True, download=True)\n",
    "mnist_testset = datasets.MNIST('data/mnist/', train=False, download=True)\n",
    "# train_data, train_labels, train_angles = get_half_labels_rotated_mnist2(mnist_trainset, rotation_range=[-60, 61])\n",
    "# test_data, test_labels, test_angles = get_rotated_mnist(mnist_testset, rotation_range=[-60, 61])\n",
    "\n",
    "train_data, train_labels = get_mnist(mnist_trainset)\n",
    "test_data, test_labels = get_mnist(mnist_testset)\n",
    "\n",
    "train_loader = init_dataloader(train_data, batch_size=200)\n",
    "test_loader = init_dataloader(test_data, batch_size=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44e9ae4-1117-456a-ae04-791ee37878a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_unseen_labels = train_data[train_labels>=5]\n",
    "train_labels_unseen_labels = train_labels[train_labels>=5]\n",
    "test_data_unseen_labels = test_data[test_labels>=5]\n",
    "test_labels_unseen_labels = test_labels[test_labels>=5]\n",
    "mnist_trainset = [[train_data_unseen_labels[i], train_labels_unseen_labels[i]-5] for i in range(len(train_data_unseen_labels))]\n",
    "mnist_testset = [[test_data_unseen_labels[i], test_labels_unseen_labels[i]-5] for i in range(len(test_data_unseen_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f1a47b-88df-4bf1-bedc-ad54d298c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = torch.flatten(train_data[train_labels==0], start_dim=1)\n",
    "temp1 = torch.flatten(train_data[train_labels==1], start_dim=1)\n",
    "temp2 = torch.flatten(train_data[train_labels==2], start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5983c433-c030-4775-8f85-5a4f4abb0f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5923, 784])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde4c493-4d21-449d-85c7-f87aa42f242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b77b842-a76f-4dd5-973a-fcd209b7b7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7db0775090>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c404825-973e-4e25-93c2-1fe4ba4a918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hog_features(X, image_shape=(28, 28), pixels_per_cell=(8, 8)):\n",
    "    fd_list = []\n",
    "    for row in X:\n",
    "        img = row.reshape(image_shape)\n",
    "        fd = hog(img, orientations=8, pixels_per_cell=pixels_per_cell, cells_per_block=(1, 1))\n",
    "        fd_list.append(fd)\n",
    "    \n",
    "    return np.array(fd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fc82f8c-043b-4461-8c5b-087a20b16c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = calc_hog_features(train_data, pixels_per_cell=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b18221e7-c6fc-4e03-8000-e0509056967d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 72)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c60e3a5a-58a2-4ae0-9514-66eecac01494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import scipy.stats as stats\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "X_train = stats.zscore(X_train)\n",
    "# X_test = stats.zscore(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17ba53e0-1167-4f54-8f33-0233422888ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 72)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "433198b8-0a3a-4ffe-94e3-0b9ac31f0b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 72)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a884f1f-c807-4daf-8698-57e9e2417239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 60000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(X_train[:5], X_train.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49068b8-a0b7-4857-97da-267f38f1d1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "904bec86-3c75-4dba-8a82-afe273e2fcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bincount(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5c31362-10ab-44fc-8cd8-af30d651ace2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=300, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9676a814-357d-4bfb-8c7c-c87f964d7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_nn(model, temp0, temp1, temp2, mnist_trainset, mnist_testset, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9c47d-6226-453c-9a99-663fa55624db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f93ec-6d2c-4c9a-b50f-f252f4974148",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datapoint in tqdm(train_loader):\n",
    "            X, y = datapoint[0].to(device), datapoint[1].to(device)\n",
    "            batch_len = X.shape[0]\n",
    "            X = X.view(-1, batch_len)    \n",
    "            emb0 = torch.mm(template0.to(device), X)\n",
    "            emb0 = [torch.histc(emb0[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb0 = torch.stack(emb0)\n",
    "            emb1 = torch.mm(template1.to(device), X)\n",
    "            emb1 = [torch.histc(emb1[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb1 = torch.stack(emb1)\n",
    "            emb2 = torch.mm(template2.to(device), X)\n",
    "            emb2 = [torch.histc(emb2[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb2 = torch.stack(emb2)\n",
    "            emb = torch.cat((emb0, emb1, emb2), dim=1)\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b69b9db8-6441-46ba-bb17-0668076d2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d1c283-5315-4915-b09c-57f7d597d686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe07b72-cca1-4491-ab7b-50474efaca4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
