{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af39f16-f17f-4cf0-b763-8606d9d731ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load utility functions for data loading and preprocessing\n",
    "from typing import Optional, Tuple, Type, Union\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as nppyth\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a6784a-bd44-44bf-9551-45671988533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist(dataset) -> Tuple[torch.Tensor]:\n",
    "    # !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "    # !tar -zxvf MNIST.tar.gz\n",
    "    imstack_data_r = torch.zeros_like(dataset.data, dtype=torch.float32)\n",
    "    labels = []\n",
    "    for i, (im, lbl) in enumerate(dataset):\n",
    "        imstack_data_r[i] = ToTensor()(im)\n",
    "        labels.append(lbl)\n",
    "    imstack_data_r /= imstack_data_r.max()\n",
    "    return imstack_data_r, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c0924-fce8-4a57-8348-b9595e3f91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotated_mnist(dataset, rotation_range: Tuple[int]) -> Tuple[torch.Tensor]:\n",
    "    # !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "    # !tar -zxvf MNIST.tar.gz\n",
    "    imstack_data_r = torch.zeros_like(dataset.data, dtype=torch.float32)\n",
    "    labels, angles = [], []\n",
    "    for i, (im, lbl) in enumerate(dataset):\n",
    "        theta = torch.randint(*rotation_range, (1,)).float()\n",
    "        im = im.rotate(theta.item(), resample=Image.BICUBIC)\n",
    "        imstack_data_r[i] = ToTensor()(im)\n",
    "        labels.append(lbl)\n",
    "        angles.append(torch.deg2rad(theta))\n",
    "    imstack_data_r /= imstack_data_r.max()\n",
    "    return imstack_data_r, torch.tensor(labels), torch.tensor(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e294df0-c451-42dd-97af-0a70bde984ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_half_labels_rotated_mnist2(dataset, rotation_range: Tuple[int]) -> Tuple[torch.Tensor]:\n",
    "    # !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "    # !tar -zxvf MNIST.tar.gz\n",
    "    data, labels, angles = [], [], []\n",
    "    count = torch.zeros(10)\n",
    "    for i, (im, lbl) in enumerate(dataset):\n",
    "        if lbl<5:\n",
    "            if count[lbl]<1000:\n",
    "                theta = torch.randint(*rotation_range, (1,)).float()\n",
    "                im = im.rotate(theta.item(), resample=Image.BICUBIC)\n",
    "                data.append(ToTensor()(im))\n",
    "                labels.append(lbl)\n",
    "                angles.append(torch.deg2rad(theta))\n",
    "                count[lbl] = count[lbl]+1\n",
    "        else:\n",
    "            if count[lbl]<1000:\n",
    "                data.append(ToTensor()(im))\n",
    "                labels.append(lbl)\n",
    "                angles.append(0)\n",
    "                count[lbl] = count[lbl]+1\n",
    "    return torch.cat(data), torch.tensor(labels), torch.tensor(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04ee57-5e12-448c-a2d9-59af1c0339ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataloader(*args: torch.Tensor, **kwargs: int\n",
    "                    ) -> Type[torch.utils.data.DataLoader]:\n",
    "\n",
    "    batch_size = kwargs.get(\"batch_size\", 100)\n",
    "    tensor_set = torch.utils.data.dataset.TensorDataset(*args)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=tensor_set, batch_size=batch_size, shuffle=True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189264aa-33da-4609-9691-958a8ace808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch.optim import Adam\n",
    "import dataclasses\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "LR = 6e-4\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels= 300, out_channels=5, num_hidden=128):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels,num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden,num_hidden)\n",
    "        self.fc3 = nn.Linear(num_hidden,out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x=torch.flatten(x, start_dim=1) # Flatten layer\n",
    "        x=F.relu(self.fc1(x)) \n",
    "        x=F.relu(self.fc2(x)) \n",
    "        x=F.softmax(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "def train_nn(model, template0, template1, template2, train_dataset, test_dataset, batch_size=32, num_epochs=NUM_EPOCHS, lr=LR, criterion=nn.CrossEntropyLoss()):\n",
    "    \n",
    "    TrainResult = {'train_losses': [], 'val_accs': []}\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle=False)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train = 0\n",
    "        model.train()\n",
    "        for datapoint in tqdm(train_loader):\n",
    "            X, y = datapoint[0].to(device), datapoint[1].to(device)\n",
    "            batch_len = X.shape[0]\n",
    "            X = X.view(-1, batch_len)    \n",
    "            emb0 = torch.mm(template0.to(device), X)\n",
    "            emb0 = [torch.histc(emb0[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb0 = torch.stack(emb0)\n",
    "            emb1 = torch.mm(template1.to(device), X)\n",
    "            emb1 = [torch.histc(emb1[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb1 = torch.stack(emb1)\n",
    "            emb2 = torch.mm(template2.to(device), X)\n",
    "            emb2 = [torch.histc(emb2[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb2 = torch.stack(emb2)\n",
    "            emb = torch.cat((emb0, emb1, emb2), dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(emb)\n",
    "            loss = criterion(output, y)\n",
    "            total_train += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_train = total_train/len(train_loader)\n",
    "        TrainResult['train_losses'].append(total_train)\n",
    "                               \n",
    "        model.eval()\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for bidx, datapoint in enumerate(test_loader):\n",
    "                X, y = datapoint[0].to(device), datapoint[1].to(device)\n",
    "                batch_len = X.shape[0]\n",
    "                X = X.view(-1, batch_len)    \n",
    "                emb0 = torch.mm(template0.to(device), X)\n",
    "                emb0 = [torch.histc(emb0[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "                emb0 = torch.stack(emb0)\n",
    "                emb1 = torch.mm(template1.to(device), X)\n",
    "                emb1 = [torch.histc(emb1[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "                emb1 = torch.stack(emb1)\n",
    "                emb2 = torch.mm(template2.to(device), X)\n",
    "                emb2 = [torch.histc(emb2[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "                emb2 = torch.stack(emb2)\n",
    "                emb = torch.cat((emb0, emb1, emb2), dim=1)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(emb)\n",
    "                total_val += torch.sum(torch.argmax(output, dim=-1)==y).item()/output.size(dim=0)\n",
    "        TrainResult['val_accs'].append(total_val/len(test_loader))\n",
    "        print(\"Epoch {}: Train Loss={} Validation Accuracy={}%\".format(epoch, TrainResult['train_losses'][-1], TrainResult['val_accs'][-1]*100))\n",
    "    return TrainResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a5456-e87d-4fa1-8201-433cef7de320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = train_nn(model, temp0, temp1, mnist_trainset, mnist_testset, num_epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5b483-b92a-4cdf-a4fb-8cd264a5bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST('data/mnist/', train=True, download=True)\n",
    "mnist_testset = datasets.MNIST('data/mnist/', train=False, download=True)\n",
    "# train_data, train_labels, train_angles = get_half_labels_rotated_mnist2(mnist_trainset, rotation_range=[-60, 61])\n",
    "# test_data, test_labels, test_angles = get_rotated_mnist(mnist_testset, rotation_range=[-60, 61])\n",
    "\n",
    "train_data, train_labels = get_mnist(mnist_trainset)\n",
    "test_data, test_labels = get_mnist(mnist_testset)\n",
    "\n",
    "train_loader = init_dataloader(train_data, batch_size=200)\n",
    "test_loader = init_dataloader(test_data, batch_size=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e9ae4-1117-456a-ae04-791ee37878a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_unseen_labels = train_data[train_labels>=5]\n",
    "train_labels_unseen_labels = train_labels[train_labels>=5]\n",
    "test_data_unseen_labels = test_data[test_labels>=5]\n",
    "test_labels_unseen_labels = test_labels[test_labels>=5]\n",
    "mnist_trainset = [[train_data_unseen_labels[i], train_labels_unseen_labels[i]-5] for i in range(len(train_data_unseen_labels))]\n",
    "mnist_testset = [[test_data_unseen_labels[i], test_labels_unseen_labels[i]-5] for i in range(len(test_data_unseen_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1a47b-88df-4bf1-bedc-ad54d298c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = torch.flatten(train_data[train_labels==0], start_dim=1)\n",
    "temp1 = torch.flatten(train_data[train_labels==1], start_dim=1)\n",
    "temp2 = torch.flatten(train_data[train_labels==2], start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983c433-c030-4775-8f85-5a4f4abb0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4c493-4d21-449d-85c7-f87aa42f242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77b842-a76f-4dd5-973a-fcd209b7b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c404825-973e-4e25-93c2-1fe4ba4a918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hog_features(X, image_shape=(28, 28), pixels_per_cell=(8, 8)):\n",
    "    fd_list = []\n",
    "    for row in X:\n",
    "        img = row.reshape(image_shape)\n",
    "        fd = hog(img, orientations=8, pixels_per_cell=pixels_per_cell, cells_per_block=(1, 1))\n",
    "        fd_list.append(fd)\n",
    "    \n",
    "    return np.array(fd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc82f8c-043b-4461-8c5b-087a20b16c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = calc_hog_features(train_data, pixels_per_cell=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18221e7-c6fc-4e03-8000-e0509056967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e3a5a-58a2-4ae0-9514-66eecac01494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import scipy.stats as stats\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "X_train = stats.zscore(X_train)\n",
    "# X_test = stats.zscore(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba53e0-1167-4f54-8f33-0233422888ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433198b8-0a3a-4ffe-94e3-0b9ac31f0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a884f1f-c807-4daf-8698-57e9e2417239",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(X_train[:5], X_train.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49068b8-a0b7-4857-97da-267f38f1d1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904bec86-3c75-4dba-8a82-afe273e2fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bincount(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c31362-10ab-44fc-8cd8-af30d651ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676a814-357d-4bfb-8c7c-c87f964d7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_nn(model, temp0, temp1, temp2, mnist_trainset, mnist_testset, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9c47d-6226-453c-9a99-663fa55624db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f93ec-6d2c-4c9a-b50f-f252f4974148",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datapoint in tqdm(train_loader):\n",
    "            X, y = datapoint[0].to(device), datapoint[1].to(device)\n",
    "            batch_len = X.shape[0]\n",
    "            X = X.view(-1, batch_len)    \n",
    "            emb0 = torch.mm(template0.to(device), X)\n",
    "            emb0 = [torch.histc(emb0[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb0 = torch.stack(emb0)\n",
    "            emb1 = torch.mm(template1.to(device), X)\n",
    "            emb1 = [torch.histc(emb1[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb1 = torch.stack(emb1)\n",
    "            emb2 = torch.mm(template2.to(device), X)\n",
    "            emb2 = [torch.histc(emb2[i], bins=100, min=0, max=784) for i in range(batch_len)]\n",
    "            emb2 = torch.stack(emb2)\n",
    "            emb = torch.cat((emb0, emb1, emb2), dim=1)\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b9db8-6441-46ba-bb17-0668076d2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d1c283-5315-4915-b09c-57f7d597d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe07b72-cca1-4491-ab7b-50474efaca4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
